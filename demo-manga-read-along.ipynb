{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuke button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Delete all files and folders in the working directory. Use with caution!\n",
    "import shutil\n",
    "shutil.rmtree(\"/kaggle/working\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clone repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working\n",
    "!git clone https://github.com/BinhPQ2/manga_read_along.git\n",
    "# !git clone -b magiv2 https://github.com/BinhPQ2/manga_read_along.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git submodule init\n",
    "!git submodule update --remote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Voice bank data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T14:34:48.717720Z",
     "iopub.status.busy": "2024-11-13T14:34:48.717341Z",
     "iopub.status.idle": "2024-11-13T14:35:32.137885Z",
     "shell.execute_reply": "2024-11-13T14:35:32.136634Z",
     "shell.execute_reply.started": "2024-11-13T14:34:48.717681Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "/kaggle/working/manga_read_along/input/voice_bank\n",
      "Dataset URL: https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio\n",
      "License(s): CC-BY-NC-SA-4.0\n",
      "Downloading ravdess-emotional-speech-audio.zip to /kaggle/working/manga_read_along/input/voice_bank\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 427M/429M [00:15<00:00, 29.6MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 429M/429M [00:15<00:00, 29.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "!cd /kaggle/working/\n",
    "\n",
    "# Step 1: Install Kaggle API if not already installed\n",
    "!pip install -q kaggle\n",
    "\n",
    "# # Step 2: Set up Kaggle authentication (move kaggle.json to ~/.kaggle/ directory)\n",
    "# mkdir -p ~/.kaggle\n",
    "# mv /path/to/kaggle.json ~/.kaggle/\n",
    "voice_bank_path = \"/kaggle/working/manga_read_along/input/voice_bank\"\n",
    "!rm -rf {voice_bank_path}\n",
    "!mkdir {voice_bank_path}\n",
    "!cd {voice_bank_path}\n",
    "\n",
    "# Step 3: Download the dataset\n",
    "!kaggle datasets download -d uwrfkaggler/ravdess-emotional-speech-audio\n",
    "\n",
    "# Step 4: Unzip the dataset\n",
    "!unzip -q ravdess-emotional-speech-audio.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import shutil\n",
    "\n",
    "def delete_unwanted_files(directory, pattern):\n",
    "    # Walk through all the directories and files in the provided path\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check if the file does not match the pattern\n",
    "            if not fnmatch.fnmatch(file, pattern):\n",
    "                file_path = os.path.join(root, file)\n",
    "#                 print(f\"Deleting file: {file_path}\")  # Optional: Print the file being deleted\n",
    "                os.remove(file_path)  # Delete the file\n",
    "    \n",
    "def copy_voice_files_by_gender(directory, pattern):\n",
    "    male_dir = os.path.join(directory, 'male')\n",
    "    female_dir = os.path.join(directory, 'female')\n",
    "    \n",
    "    # Remove the existing male and female directories if they exist\n",
    "    if os.path.exists(male_dir):\n",
    "        shutil.rmtree(male_dir)  # Remove the existing male directory\n",
    "    if os.path.exists(female_dir):\n",
    "        shutil.rmtree(female_dir)  # Remove the existing female directory\n",
    "\n",
    "    # Recreate the directories\n",
    "    os.makedirs(male_dir, exist_ok=True)\n",
    "    os.makedirs(female_dir, exist_ok=True)\n",
    "\n",
    "    # List to store all the files that need to be copied\n",
    "    files_to_copy = []\n",
    "\n",
    "    # Walk through the directory to gather the .wav files\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if fnmatch.fnmatch(file, pattern):  # Check if the file matches the desired pattern\n",
    "                actor_number = file.split('-')[-1].split('.wav')[0]  # Extract the actor number from filename\n",
    "\n",
    "                # Determine whether the actor is male or female\n",
    "                if int(actor_number) % 2 == 0:  # Even actor number (female)\n",
    "                    dest_dir = female_dir\n",
    "                else:  # Odd actor number (male)\n",
    "                    dest_dir = male_dir\n",
    "\n",
    "                # Append the file with its destination directory to the files_to_copy list\n",
    "                source_file = os.path.join(root, file)\n",
    "                destination_file = os.path.join(dest_dir, file)\n",
    "                files_to_copy.append((source_file, destination_file))\n",
    "\n",
    "    # Now copy all the files that need to be copied\n",
    "    for source_file, destination_file in files_to_copy:\n",
    "        shutil.copy(source_file, destination_file)\n",
    "#         print(f\"Copied: {source_file} -> {destination_file}\")\n",
    "\n",
    "# Define the path to the voice bank folder\n",
    "file_pattern = \"03-01-01-01-01-01-*.wav\"\n",
    "\n",
    "# Run the function to delete unwanted files\n",
    "delete_unwanted_files(voice_bank_path, file_pattern)\n",
    "copy_voice_files_by_gender(voice_bank_path, file_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def delete_other_folders(directory, keep_folders=[\"male\", \"female\"]):\n",
    "    for root, dirs, _ in os.walk(directory):\n",
    "        for dir in dirs:\n",
    "            dir_path = os.path.join(root, dir)\n",
    "            # Delete any folder that is not in the keep_folders list\n",
    "            if dir not in keep_folders:\n",
    "                shutil.rmtree(dir_path)\n",
    "                print(f\"Deleted directory: {dir_path}\")\n",
    "                \n",
    "delete_other_folders(voice_bank_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/manga_read_along\n",
    "\n",
    "raw_image_path = \"input/raw\"\n",
    "character_path = \"input/character\"\n",
    "voice_bank_path = \"input/voice_bank\"\n",
    "\n",
    "raw_image_rename_path = \"output/renamed\"\n",
    "colorized_path = \"output/colorized\"\n",
    "json_path = \"output/json\"\n",
    "transcript_path = \"output/transcript\"\n",
    "audio_path = \"output/audio\"\n",
    "final_output_path =\"output/output_final\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cat /kaggle/working/manga_read_along/magi_functional/requirements_kaggle.txt | xargs -n 1 pip install -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from transformers import AutoModel\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import argparse\n",
    "import torch\n",
    "from TTS.api import TTS\n",
    "from unittest.mock import patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check GPU and set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:09:29.501270Z",
     "iopub.status.busy": "2024-11-06T18:09:29.500348Z",
     "iopub.status.idle": "2024-11-06T18:09:34.804845Z",
     "shell.execute_reply": "2024-11-06T18:09:34.803464Z",
     "shell.execute_reply.started": "2024-11-06T18:09:29.501230Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  6 18:09:33 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P0             25W /  250W |       3MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Wed_Nov_22_10:17:15_PST_2023\n",
      "Cuda compilation tools, release 12.3, V12.3.107\n",
      "Build cuda_12.3.r12.3/compiler.33567101_0\n",
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    !nvidia-smi\n",
    "    !nvcc --version\n",
    "else:\n",
    "    print(\"GPU is not available\")\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Running on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MAGI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:10:09.633204Z",
     "iopub.status.busy": "2024-11-06T18:10:09.631988Z",
     "iopub.status.idle": "2024-11-06T18:11:27.076099Z",
     "shell.execute_reply": "2024-11-06T18:11:27.075081Z",
     "shell.execute_reply.started": "2024-11-06T18:10:09.633159Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e70250beb448eaa328e5e5f866f610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/13.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba100957c0241cc8315145ab9cd4ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_magiv2.py:   0%|          | 0.00/1.70k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ragavsachdeva/magiv2:\n",
      "- configuration_magiv2.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e12a726a9245ec9188c1e0241f77b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modelling_magiv2.py:   0%|          | 0.00/34.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723b8cac254f4bbbbad877492a542767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "utils.py:   0%|          | 0.00/16.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ragavsachdeva/magiv2:\n",
      "- utils.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203b56455912450cb796ba04ee095c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processing_magiv2.py:   0%|          | 0.00/10.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ragavsachdeva/magiv2:\n",
      "- processing_magiv2.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/ragavsachdeva/magiv2:\n",
      "- modelling_magiv2.py\n",
      "- utils.py\n",
      "- processing_magiv2.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac099a93242426188ae3314555296c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee51423d5f534419a0d0bf8f8be32a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/224 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4882bcf1af944ba9ae6fe120e098e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c36d096167b412bacdea6a44536f6e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebe5a36ac0f48c7881620dac161f279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4d3ba4c6454e928b22f78ef577421d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "VisionEncoderDecoderModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39eb0178f8164ead98f4e7dd180998cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "magiv2 = AutoModel.from_pretrained(\"ragavsachdeva/magiv2\", trust_remote_code=True).to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download weight for colorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:11:43.169757Z",
     "iopub.status.busy": "2024-11-06T18:11:43.169307Z",
     "iopub.status.idle": "2024-11-06T18:11:59.679324Z",
     "shell.execute_reply": "2024-11-06T18:11:59.678346Z",
     "shell.execute_reply.started": "2024-11-06T18:11:43.169709Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1qmxUEKADkEM4iYLp1fpPLLKnfZ6tcF-t\n",
      "From (redirected): https://drive.google.com/uc?id=1qmxUEKADkEM4iYLp1fpPLLKnfZ6tcF-t&confirm=t&uuid=b8e27ce6-40aa-4a91-a04e-4dae4bb50a03\n",
      "To: /kaggle/working/manga_read_along/manga-colorization-v2-custom/networks/generator.zip\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129M/129M [00:03<00:00, 35.4MB/s]\n",
      "mkdir: cannot create directory '/kaggle/working/manga_read_along/manga-colorization-v2-custom/denoising/models': File exists\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=161oyQcYpdkVdw8gKz_MA8RD-Wtg9XDp3\n",
      "To: /kaggle/working/manga_read_along/manga-colorization-v2-custom/denoising/models/net_rgb.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.44M/3.44M [00:00<00:00, 211MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown 1qmxUEKADkEM4iYLp1fpPLLKnfZ6tcF-t -O /kaggle/working/manga_read_along/manga-colorization-v2-custom/networks/generator.zip\n",
    "!mkdir /kaggle/working/manga_read_along/manga-colorization-v2-custom/denoising/models\n",
    "!gdown 161oyQcYpdkVdw8gKz_MA8RD-Wtg9XDp3 -O /kaggle/working/manga_read_along/manga-colorization-v2-custom/denoising/models/net_rgb.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download weight for Text-to-Speech model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:14:07.206419Z",
     "iopub.status.busy": "2024-11-06T18:14:07.205975Z",
     "iopub.status.idle": "2024-11-06T18:15:34.224206Z",
     "shell.execute_reply": "2024-11-06T18:15:34.223402Z",
     "shell.execute_reply.started": "2024-11-06T18:14:07.206370Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > You must confirm the following:\n",
      " | > \"I have purchased a commercial license from Coqui: licensing@coqui.ai\"\n",
      " | > \"Otherwise, I agree to the terms of the non-commercial CPML: https://coqui.ai/cpml\" - [y/n]\n",
      " > Downloading model to /root/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.87G/1.87G [00:44<00:00, 42.8MiB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.87G/1.87G [00:44<00:00, 41.7MiB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.37k/4.37k [00:00<00:00, 9.86kiB/s]\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 361k/361k [00:00<00:00, 459kiB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32.0/32.0 [00:00<00:00, 49.9iB/s]\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3.49M/7.75M [00:00<00:00, 34.9MiB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Model's license - CPML\n",
      " > Check https://coqui.ai/cpml.txt for more info.\n",
      " > Using model: xtts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.speakers = torch.load(speaker_file_path)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.75M/7.75M [00:13<00:00, 34.9MiB/s]/opt/conda/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location, **kwargs)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "# Mock input to automatically respond with 'y'\n",
    "with patch('builtins.input', return_value='y'):\n",
    "    tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magiv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:12:21.453339Z",
     "iopub.status.busy": "2024-11-06T18:12:21.452413Z",
     "iopub.status.idle": "2024-11-06T18:12:49.103028Z",
     "shell.execute_reply": "2024-11-06T18:12:49.101733Z",
     "shell.execute_reply.started": "2024-11-06T18:12:21.453284Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "VisionEncoderDecoderModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.71s/it]\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /opt/conda/lib/python3.10/site-packages/pulp/solverdir/cbc/linux/64/cbc /tmp/7a6c3a1eb7114afc88f91e0d135d1d7a-pulp.mps -timeMode elapsed -branch -printingOptions all -solution /tmp/7a6c3a1eb7114afc88f91e0d135d1d7a-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 496 COLUMNS\n",
      "At line 2087 RHS\n",
      "At line 2579 BOUNDS\n",
      "At line 2740 ENDATA\n",
      "Problem MODEL has 491 rows, 160 columns and 1110 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Continuous objective value is 8.59924 - 0.00 seconds\n",
      "Cgl0003I 0 fixed, 0 tightened bounds, 27 strengthened rows, 0 substitutions\n",
      "Cgl0003I 0 fixed, 0 tightened bounds, 27 strengthened rows, 0 substitutions\n",
      "Cgl0003I 0 fixed, 0 tightened bounds, 18 strengthened rows, 0 substitutions\n",
      "Cgl0003I 0 fixed, 0 tightened bounds, 9 strengthened rows, 0 substitutions\n",
      "Cgl0003I 0 fixed, 0 tightened bounds, 9 strengthened rows, 0 substitutions\n",
      "Cgl0005I 4 SOS with 40 members\n",
      "Cgl0004I processed model has 13 rows, 40 columns (40 integer (40 of which binary)) and 76 elements\n",
      "Cbc0038I Initial state - 0 integers unsatisfied sum - 0\n",
      "Cbc0038I Solution found of 8.59924\n",
      "Cbc0038I Before mini branch and bound, 40 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Mini branch and bound did not improve solution (0.01 seconds)\n",
      "Cbc0038I After 0.01 seconds - Feasibility pump exiting with objective of 8.59924 - took 0.00 seconds\n",
      "Cbc0012I Integer solution of 8.5992398 found by feasibility pump after 0 iterations and 0 nodes (0.01 seconds)\n",
      "Cbc0001I Search completed - best objective 8.599239811676402, took 0 iterations and 0 nodes (0.01 seconds)\n",
      "Cbc0035I Maximum depth 0, 0 variables fixed on reduced cost\n",
      "Cuts at root node changed objective from 8.59924 to 8.59924\n",
      "Probing was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Gomory was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Knapsack was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Clique was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "MixedIntegerRounding2 was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "FlowCover was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "TwoMirCuts was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "ZeroHalf was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                8.59923981\n",
      "Enumerated nodes:               0\n",
      "Total iterations:               0\n",
      "Time (CPU seconds):             0.01\n",
      "Time (Wallclock seconds):       0.01\n",
      "\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.01   (Wallclock seconds):       0.01\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.97s/it]\n",
      "\n",
      "\n",
      "Done you WEEEEB!\n"
     ]
    }
   ],
   "source": [
    "# Test module magiv2 (worked)\n",
    "!python /kaggle/working/manga_read_along/magi_functional/magiv2.py --image {raw_image_path} --rename_image {raw_image_rename_path} --character {character_path} --json {json_path} --transcript {transcript_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:15:36.586483Z",
     "iopub.status.busy": "2024-11-06T18:15:36.585656Z",
     "iopub.status.idle": "2024-11-06T18:15:44.091903Z",
     "shell.execute_reply": "2024-11-06T18:15:44.090908Z",
     "shell.execute_reply.started": "2024-11-06T18:15:36.586431Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: output/renamed/001.jpg\n",
      "Saved colorized image to: output/colorized/001.jpg\n",
      "Processing: output/renamed/002.jpg\n",
      "Saved colorized image to: output/colorized/002.jpg\n",
      "Processing: output/renamed/000.jpg\n",
      "Saved colorized image to: output/colorized/000.jpg\n"
     ]
    }
   ],
   "source": [
    "!python \"/kaggle/working/manga_read_along/manga-colorization-v2-custom/inference_v2.py\" -p {raw_image_rename_path} -des_path \"/kaggle/working/manga_read_along/manga-colorization-v2-custom/denoising/models/net_rgb.pth\" -gen \"/kaggle/working/manga_read_along/manga-colorization-v2-custom/networks/generator.zip\" -s {colorized_path} -ds 0 --gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:15:56.325886Z",
     "iopub.status.busy": "2024-11-06T18:15:56.325206Z",
     "iopub.status.idle": "2024-11-06T18:15:56.330308Z",
     "shell.execute_reply": "2024-11-06T18:15:56.329146Z",
     "shell.execute_reply.started": "2024-11-06T18:15:56.325846Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "raw_image_rename_path = \"input/raw\"\n",
    "transcript_path = \"input/transcript\"\n",
    "voice_bank_path = \"input/voice_bank\"\n",
    "output_path = \"output\"\n",
    "transcript_file = f\"{transcript_path}/transcript.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:15:59.348619Z",
     "iopub.status.busy": "2024-11-06T18:15:59.348217Z",
     "iopub.status.idle": "2024-11-06T18:16:54.917368Z",
     "shell.execute_reply": "2024-11-06T18:16:54.916310Z",
     "shell.execute_reply.started": "2024-11-06T18:15:59.348573Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n",
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n",
      "/opt/conda/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.speakers = torch.load(speaker_file_path)\n",
      "/opt/conda/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location, **kwargs)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      " > Text splitted to sentences.\n",
      "['Eh...?']\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      " > Processing time: 2.1704838275909424\n",
      " > Real-time factor: 0.8126047337404965\n",
      " > Text splitted to sentences.\n",
      "['All of a sudden']\n",
      " > Processing time: 1.054344654083252\n",
      " > Real-time factor: 0.33751886792299224\n",
      " > Text splitted to sentences.\n",
      "['I grew horns']\n",
      " > Processing time: 0.8201084136962891\n",
      " > Real-time factor: 0.36213133855341184\n",
      " > Text splitted to sentences.\n",
      "['Am I really human?']\n",
      " > Processing time: 0.9328665733337402\n",
      " > Real-time factor: 0.3361063389217152\n",
      " > Text splitted to sentences.\n",
      "['Mom, about this...']\n",
      " > Processing time: 1.5902233123779297\n",
      " > Real-time factor: 0.36229566909750943\n",
      " > Text splitted to sentences.\n",
      "['Oh, Mor- Ning Honey.']\n",
      " > Processing time: 2.2786009311676025\n",
      " > Real-time factor: 0.3498047129626103\n",
      " > Text splitted to sentences.\n",
      "['This thing on my head ...']\n",
      " > Processing time: 1.121250867843628\n",
      " > Real-time factor: 0.33643018773067707\n",
      " > Text splitted to sentences.\n",
      "[\"It's horns.\"]\n",
      " > Processing time: 0.5612871646881104\n",
      " > Real-time factor: 0.31793007555931035\n",
      " > Text splitted to sentences.\n",
      "['You know this?']\n",
      " > Processing time: 0.4873332977294922\n",
      " > Real-time factor: 0.31310312397830137\n",
      " > Text splitted to sentences.\n",
      "['But why did they...']\n",
      " > Processing time: 1.174865484237671\n",
      " > Real-time factor: 0.3429594355994578\n",
      " > Text splitted to sentences.\n",
      "[\"Ah, that's because you're not a human.\"]\n",
      " > Processing time: 1.3432955741882324\n",
      " > Real-time factor: 0.3372616529747054\n",
      " > Text splitted to sentences.\n",
      "['Since your Dad']\n",
      " > Processing time: 0.628460168838501\n",
      " > Real-time factor: 0.3381869075285276\n",
      " > Text splitted to sentences.\n",
      "['Is a Dragon']\n",
      " > Processing time: 0.4683353900909424\n",
      " > Real-time factor: 0.3101512299226718\n",
      " > Text splitted to sentences.\n",
      "[\"According to your Dad, your body will start to change when you're 15.\"]\n",
      " > Processing time: 1.58674955368042\n",
      " > Real-time factor: 0.34507483488493434\n",
      " > Text splitted to sentences.\n",
      "[\"I didn't expect the horns to grow overnight though.\"]\n",
      " > Processing time: 1.1387364864349365\n",
      " > Real-time factor: 0.3369811510346032\n",
      " > Text splitted to sentences.\n",
      "['Anyways, eat your breakfast.']\n",
      " > Processing time: 1.0425641536712646\n",
      " > Real-time factor: 0.3337476711447646\n",
      "Audio files have been saved to output/audio\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python /kaggle/working/magi_functional/text_to_speech.py -i {raw_image_rename_path} -v {voice_bank_path} -t {transcript_file} -o {output_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:17:03.337432Z",
     "iopub.status.busy": "2024-11-06T18:17:03.337102Z",
     "iopub.status.idle": "2024-11-06T18:17:11.525432Z",
     "shell.execute_reply": "2024-11-06T18:17:11.524190Z",
     "shell.execute_reply.started": "2024-11-06T18:17:03.337398Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted images\n",
      "Processed and saved modified panel view images for: 000.jpg\n",
      "Processed and saved modified panel view images for: 001.jpg\n",
      "Processed and saved modified panel view images for: 002.jpg\n",
      "Video saved as: output/output_final/video_Padding_True.mp4\n",
      "Audio file not found for image: page_000_panel_000_bubble_000.jpg. Appending silence for 1 seconds.\n",
      "Audio file not found for image: page_001_panel_000_bubble_000.jpg. Appending silence for 1 seconds.\n",
      "Audio file not found for image: page_001_panel_001_bubble_000.jpg. Appending silence for 1 seconds.\n",
      "Audio file not found for image: page_001_panel_002_bubble_000.jpg. Appending silence for 1 seconds.\n",
      "Audio file not found for image: page_001_panel_003_bubble_000.jpg. Appending silence for 1 seconds.\n",
      "Audio file not found for image: page_002_panel_000_bubble_000.jpg. Appending silence for 1 seconds.\n",
      "Audio file not found for image: page_002_panel_001_bubble_000.jpg. Appending silence for 1 seconds.\n",
      "Audio file not found for image: page_002_panel_002_bubble_000.jpg. Appending silence for 1 seconds.\n",
      "Audio file not found for image: page_002_panel_003_bubble_000.jpg. Appending silence for 1 seconds.\n",
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'output/output_final/video_Padding_True.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:00:54.75, start: 0.000000, bitrate: 992 kb/s\n",
      "  Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 860x1250 [SAR 1:1 DAR 86:125], 991 kb/s, 24 fps, 24 tbr, 12288 tbn, 24 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "\u001b[0;33mGuessed Channel Layout for Input Stream #1.0 : mono\n",
      "\u001b[0mInput #1, wav, from 'output/output_final/temp_audio.wav':\n",
      "  Duration: 00:00:55.19, bitrate: 384 kb/s\n",
      "  Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, mono, s16, 384 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #1:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp4, to 'output/output_final/video_Padding_True_audio.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 860x1250 [SAR 1:1 DAR 86:125], q=2-31, 991 kb/s, 24 fps, 24 tbr, 12288 tbn, 12288 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 24000 Hz, mono, fltp, 69 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 aac\n",
      "frame= 1314 fps=0.0 q=-1.0 Lsize=    7030kB time=00:00:54.74 bitrate=1052.1kbits/s speed= 185x    \n",
      "video:6630kB audio:378kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.324392%\n",
      "\u001b[1;36m[aac @ 0x57b7bf850640] \u001b[0mQavg: 21190.207\n",
      "Audio merged successfully into video saved as: output/output_final/video_Padding_True_audio.mp4\n",
      "Temporary audio file 'output/output_final/temp_audio.wav' deleted. Original video 'output/output_final/video_Padding_True.mp4' deleted.\n"
     ]
    }
   ],
   "source": [
    "!python /kaggle/working/manga_read_along/magi_functional/main.py -i {colorized_path} -j {json_path} -a {audio_path} -s {final_output_path} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download separate files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "def download_file(download_file_name, source_path):\n",
    "    os.chdir('/kaggle/working/')\n",
    "    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n",
    "    command = f\"zip -rj {zip_name} {source_path}\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"Unable to run zip command!\")\n",
    "        print(result.stderr)\n",
    "        return\n",
    "    display(FileLink(f'{download_file_name}.zip'))\n",
    "\n",
    "download_file(\"json_results\", f\"{json_output_dir}/*.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download image results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "def download_file(download_file_name, source_path):\n",
    "    os.chdir('/kaggle/working/')\n",
    "    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n",
    "    command = f\"zip -rj {zip_name} {source_path}\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"Unable to run zip command!\")\n",
    "        print(result.stderr)\n",
    "        return\n",
    "    display(FileLink(f'{download_file_name}.zip'))\n",
    "\n",
    "download_file(\"image_results\", result_image_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "def download_file(download_file_name, source_path):\n",
    "    os.chdir('/kaggle/working/')\n",
    "    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n",
    "    command = f\"zip -rj {zip_name} {source_path}\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"Unable to run zip command!\")\n",
    "        print(result.stderr)\n",
    "        return\n",
    "    display(FileLink(f'{download_file_name}.zip'))\n",
    "\n",
    "download_file(\"audio_results\", \"/kaggle/working/manga_read_along/test/audio_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!rm -rf /kaggle/working/audio_results.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "def download_file(download_file_name, source_path):\n",
    "    os.chdir('/kaggle/working/')\n",
    "    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n",
    "    command = f\"zip -rj {zip_name} {source_path}\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"Unable to run zip command!\")\n",
    "        print(result.stderr)\n",
    "        return\n",
    "    display(FileLink(f'{download_file_name}.zip'))\n",
    "download_file(\"transcript\", \"/kaggle/working/result/transcript.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T14:56:08.662472Z",
     "iopub.status.busy": "2024-11-13T14:56:08.661589Z",
     "iopub.status.idle": "2024-11-13T14:56:09.952291Z",
     "shell.execute_reply": "2024-11-13T14:56:09.951062Z",
     "shell.execute_reply.started": "2024-11-13T14:56:08.662425Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='male.zip' target='_blank'>male.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/male.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!cd /kaggle/working/\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "def download_file(download_file_name, source_path):\n",
    "    os.chdir('/kaggle/working/')\n",
    "    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n",
    "    command = f\"zip -rj {zip_name} {source_path}\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"Unable to run zip command!\")\n",
    "        print(result.stderr)\n",
    "        return\n",
    "    display(FileLink(f'{download_file_name}.zip'))\n",
    "\n",
    "download_file(\"male\", \"/kaggle/working/manga_read_along/input/voice_bank/male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T14:57:04.119327Z",
     "iopub.status.busy": "2024-11-13T14:57:04.118730Z",
     "iopub.status.idle": "2024-11-13T14:57:05.384183Z",
     "shell.execute_reply": "2024-11-13T14:57:05.382908Z",
     "shell.execute_reply.started": "2024-11-13T14:57:04.119283Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='female.zip' target='_blank'>female.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/female.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!cd /kaggle/working/\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "def download_file(download_file_name, source_path):\n",
    "    os.chdir('/kaggle/working/')\n",
    "    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n",
    "    command = f\"zip -rj {zip_name} {source_path}\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"Unable to run zip command!\")\n",
    "        print(result.stderr)\n",
    "        return\n",
    "    display(FileLink(f'{download_file_name}.zip'))\n",
    "\n",
    "download_file(\"female\", \"/kaggle/working/manga_read_along/input/voice_bank/female\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "def download_file(download_file_name, source_path):\n",
    "    os.chdir('/kaggle/working/')\n",
    "    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n",
    "    command = f\"zip -r {zip_name} {source_path}\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"Unable to run zip command!\")\n",
    "        print(result.stderr)\n",
    "        return\n",
    "    display(FileLink(f'{download_file_name}.zip'))\n",
    "    \n",
    "\n",
    "!cp -r result_dir /\n",
    "download_file(\"result\", result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "process_file = '''\n",
    "TTS==0.22.0\n",
    "einops==0.8.0\n",
    "PuLP==2.9.0\n",
    "Pillow==9.5.0\n",
    "gdown==5.2.0\n",
    "pydub==0.25.1\n",
    "numpy==1.26.4\n",
    "pandas==2.2.2\n",
    "'''\n",
    "\n",
    "with open(\"/kaggle/working/manga_read_along/magi_functional/requirements_kaggle.txt\", \"w\") as file:\n",
    "    file.write(process_file)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experienmental notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download kaggle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T19:35:35.411928Z",
     "iopub.status.busy": "2024-11-11T19:35:35.411480Z",
     "iopub.status.idle": "2024-11-11T19:35:36.718065Z",
     "shell.execute_reply": "2024-11-11T19:35:36.716502Z",
     "shell.execute_reply.started": "2024-11-11T19:35:35.411887Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!rm -rf /kaggle/working/Actor_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/\n",
    "\n",
    "# Step 1: Install Kaggle API if not already installed\n",
    "!pip install -q kaggle\n",
    "\n",
    "# # Step 2: Set up Kaggle authentication (move kaggle.json to ~/.kaggle/ directory)\n",
    "# mkdir -p ~/.kaggle\n",
    "# mv /path/to/kaggle.json ~/.kaggle/\n",
    "voice_bank_path = \"/kaggle/working/manga_read_along/input/voice_bank\"\n",
    "!mkdir {voice_bank_path}\n",
    "%cd {voice_bank_path}\n",
    "\n",
    "# Step 3: Download the dataset\n",
    "!kaggle datasets download -d uwrfkaggler/ravdess-emotional-speech-audio\n",
    "\n",
    "# Step 4: Unzip the dataset\n",
    "!unzip ravdess-emotional-speech-audio.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_voice_files(directory):\n",
    "    all_files = []\n",
    "    # Walk through the directory and subdirectories\n",
    "    for root, _, files in os.walk(directory):\n",
    "#         print(f\"Checking in directory: {root}\")  # Debug: Print the current directory being checked\n",
    "        for file in files:\n",
    "            # Check if the file is a .wav file (case insensitive)\n",
    "            if file.lower().endswith(\".wav\"):\n",
    "                all_files.append(os.path.join(root, file))\n",
    "#                 print(f\"Found file: {file}\")  # Debug: Print the file name found\n",
    "    return all_files\n",
    "\n",
    "# Get all .wav files in the voice_bank directory\n",
    "all_files = get_voice_files(voice_bank_path)\n",
    "\n",
    "# Print the list of all found files\n",
    "print(f\"All found voice files: {all_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magiv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create raw and character/names list (should apply rename first dumbass, TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def create_chapter_pages_and_character_bank(manga_folder, character_folder):\n",
    "    # Create lists for chapter pages and character bank\n",
    "    chapter_pages = []\n",
    "    character_bank = {\n",
    "        \"images\": [],\n",
    "        \"names\": []\n",
    "    }\n",
    "\n",
    "#     Iterate through manga images to create chapter_pages\n",
    "    for image_file in os.listdir(manga_folder):\n",
    "        if image_file.endswith(('.png', '.jpg', '.jpeg')):  # Check for image file extensions\n",
    "            # Extract the page number using regex\n",
    "            match = re.search(r'p(\\d+)', image_file)\n",
    "            if match:\n",
    "                page_number = int(match.group(1))  # Convert to integer for sorting\n",
    "                chapter_pages.append((page_number, image_file))  # Store as tuple (page_number, image_file)\n",
    "            else:\n",
    "                page_number = image_file.rsplit(\".\", 1)[0]\n",
    "                chapter_pages.append((page_number, image_file))  # Store as tuple (page_number, image_file)\n",
    "\n",
    "    # Sort chapter pages by page number\n",
    "    chapter_pages.sort(key=lambda x: x[0])\n",
    "    chapter_pages = [os.path.join(manga_folder, img[1]) for img in chapter_pages]  # Extract just the filenames after sorting\n",
    "\n",
    "    # Iterate through character images to create character bank\n",
    "    for char_image_file in os.listdir(character_folder):\n",
    "        if char_image_file.endswith(('.png', '.jpg', '.jpeg')):  # Check for image file extensions\n",
    "            # Split the filename to extract character name\n",
    "            char_name = char_image_file.split('_')[0]  # Get the part before the underscore\n",
    "            character_bank[\"images\"].append(os.path.join(character_folder, char_image_file))\n",
    "            character_bank[\"names\"].append(char_name)\n",
    "    return chapter_pages, character_bank\n",
    "\n",
    "# Define your folders\n",
    "# One Piece\n",
    "# manga_folder = Path(\"/kaggle/working/magi_functional/data_test/personal_data/One_Piece/raw_manga\")\n",
    "# character_folder = Path(\"/kaggle/working/magi_functional/data_test/personal_data/One_Piece/character\")\n",
    "\n",
    "# Ruri Dragon\n",
    "manga_folder = Path(\"/kaggle/working/manga_read_along/magi_functional/data_test/personal_data/Ruri_Dragon/raw\")\n",
    "character_folder = Path(\"/kaggle/working/manga_read_along/magi_functional/data_test/personal_data/Ruri_Dragon/character\")\n",
    "\n",
    "# Get chapter pages and character bank\n",
    "chapter_pages_original, character_bank_original = create_chapter_pages_and_character_bank(manga_folder, character_folder)\n",
    "\n",
    "chapter_pages_test = chapter_pages_original\n",
    "character_bank_test = character_bank_original\n",
    "\n",
    "# Print the results (for debugging)\n",
    "print(\"Chapter Pages:\")\n",
    "print(chapter_pages_test)\n",
    "\n",
    "print(\"\\nCharacter Bank:\")\n",
    "print(character_bank_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process (OCR â†’ Transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def read_image(path_to_image):\n",
    "    with open(path_to_image, \"rb\") as file:\n",
    "        image = Image.open(file).convert(\"L\").convert(\"RGB\")\n",
    "        image = np.array(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "chapter_pages = [read_image(x) for x in chapter_pages_test]\n",
    "character_bank = character_bank_test.copy()\n",
    "character_bank[\"images\"] = [read_image(x) for x in character_bank_test[\"images\"]]\n",
    "\n",
    "with torch.no_grad():\n",
    "    per_page_results = magiv2.do_chapter_wide_prediction(chapter_pages, character_bank, use_tqdm=True, do_ocr=True)\n",
    "\n",
    "print(\"Continue with next cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save transcript and json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"/kaggle/working/result\"\n",
    "json_output_dir = f\"{result_dir}/json_results\"\n",
    "result_image_output_dir = f\"{result_dir}/image_results\"\n",
    "transcript_output_dir = f\"{result_dir}/transcript.txt\"\n",
    "os.makedirs(json_output_dir, exist_ok=True)  # Create the directory if it doesn't exist  \n",
    "os.makedirs(result_image_output_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "transcript = []\n",
    "for i, (image, page_result) in enumerate(zip(chapter_pages, per_page_results)):\n",
    "    image_name_ext = os.path.basename(chapter_pages_test[i]) \n",
    "    # Split the image name and its extension\n",
    "    image_name, image_extension = os.path.splitext(image_name_ext)\n",
    "    \n",
    "#     model.visualise_single_image_prediction(image, page_result, os.path.join(result_image_output_dir, f\"{image_name}.png\")) # enable this if you want to see the result image included with all the annotation box\n",
    "    # Save page_result to JSON\n",
    "    json_file_path = os.path.join(json_output_dir, f\"{image_name}.json\")\n",
    "    with open(json_file_path, 'w') as json_file:\n",
    "        json.dump(page_result, json_file, indent=4)\n",
    "\n",
    "    speaker_name = {\n",
    "        text_idx: page_result[\"character_names\"][char_idx] for text_idx, char_idx in page_result[\"text_character_associations\"]\n",
    "    }\n",
    "    \n",
    "    transcript.append(f\"<page>{image_name}<endpage>\")\n",
    "    for j in range(len(page_result[\"ocr\"])):\n",
    "        if not page_result[\"is_essential_text\"][j]:\n",
    "            continue\n",
    "        name = speaker_name.get(j, \"unsure\") \n",
    "        transcript.append(f\"<name>{name}<endname>: {page_result['ocr'][j]}\")\n",
    "with open(transcript_output_dir, \"w\") as fh:\n",
    "    for line in transcript:\n",
    "        fh.write(line + \"\\n\")\n",
    "\n",
    "print(\"\\n\\nDone you WEEEEB!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_mapping = {\n",
    "'other': \"/kaggle/input/ravdess-emotional-speech-audio/Actor_02/03-01-01-01-01-01-02.wav\",\n",
    "'ruri': \"/kaggle/input/ravdess-emotional-speech-audio/Actor_04/03-01-01-01-01-01-04.wav\",\n",
    "'teacher': \"/kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-01-01-01-01-01.wav\",\n",
    "'mom': \"/kaggle/input/ravdess-emotional-speech-audio/Actor_08/03-01-01-01-01-01-08.wav\",\n",
    "'unsure': \"/kaggle/input/ravdess-emotional-speech-audio/Actor_10/03-01-01-01-01-01-10.wav\",\n",
    "'ukka': \"/kaggle/input/ravdess-emotional-speech-audio/Actor_12/03-01-01-01-01-01-12.wav\"\n",
    "}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from magi_functional.utils.utils import rename_image_to_correct_format, get_digit_number_for_name_format, generate_name_format\n",
    "\n",
    "images_folder = '/kaggle/working/manga_read_along/input/colorized'\n",
    "\n",
    "number_of_digit_for_name = get_digit_number_for_name_format(images_folder)\n",
    "name_format = generate_name_format(number_of_digit_for_name)\n",
    "print(name_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to parse the transcript from a text file\n",
    "def parse_transcript(transcript_path, line_end: int = None):\n",
    "    pages = []\n",
    "    current_page = None\n",
    "\n",
    "    with open(transcript_path, 'r') as file:\n",
    "        content = file.readlines()\n",
    "        \n",
    "    lines_to_process = content[:line_end] if line_end is not None else content\n",
    "    \n",
    "    for line in lines_to_process:\n",
    "        if line.startswith(\"<page>\"):\n",
    "            # Start a new page\n",
    "            if current_page is not None:\n",
    "                pages.append(current_page)\n",
    "            current_page = {\"page\": re.search(r'<page>(\\d+)<endpage>', line).group(1), \"lines\": []}      \n",
    "        elif line.startswith(\"<name>\") and current_page is not None:\n",
    "            # Extract character name and dialogue\n",
    "            match = re.match(r\"<name>([^<]+)<endname>:\\s*(.+)\", line)\n",
    "            if match:\n",
    "                character = match.group(1).lower()  # Lowercase for consistency\n",
    "                dialogue = match.group(2)\n",
    "                current_page[\"lines\"].append((character, dialogue))\n",
    "\n",
    "    # Add the last page if it exists\n",
    "    if current_page is not None:\n",
    "        pages.append(current_page)\n",
    "        \n",
    "    return pages\n",
    "\n",
    "# Function to get all voice files from the specified directory\n",
    "def get_voice_files(directory):\n",
    "    all_files = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                all_files.append(os.path.join(root, file))\n",
    "    return all_files\n",
    "\n",
    "# Function to filter voice files into male and female categories\n",
    "def filter_voice_files(files):\n",
    "    male_files = []\n",
    "    female_files = []\n",
    "    \n",
    "    for file in files:\n",
    "        # Extract the actor number from the filename\n",
    "        match = re.search(r\"(\\d{2})\\.wav$\", file)\n",
    "        if match:\n",
    "            actor_number = int(match.group(1))\n",
    "            if actor_number % 2 == 0:  # Even numbers are female\n",
    "                female_files.append(file)\n",
    "            else:  # Odd numbers are male\n",
    "                male_files.append(file)\n",
    "                \n",
    "    return male_files, female_files\n",
    "\n",
    "# Function to randomly select voice files for characters\n",
    "def select_voice_files_for_characters(characters):\n",
    "    all_files = get_voice_files(voice_bank)\n",
    "    male_files, female_files = filter_voice_files(all_files)\n",
    "\n",
    "    selected_files = {}\n",
    "    used_files = set()  # To keep track of used voice files\n",
    "\n",
    "    for character in characters:\n",
    "        if character in male_characters:\n",
    "            # Select a random male voice that hasn't been used\n",
    "            available_male_files = list(set(male_files) - used_files)\n",
    "            if available_male_files:\n",
    "                selected_files[character] = random.choice(available_male_files)\n",
    "                used_files.add(selected_files[character])\n",
    "        else:\n",
    "            # Select a random female voice that hasn't been used, if available\n",
    "            available_female_files = list(set(female_files) - used_files)\n",
    "            if available_female_files:\n",
    "                selected_files[character] = random.choice(available_female_files)\n",
    "                used_files.add(selected_files[character])\n",
    "            else:\n",
    "                # Select any remaining file for other characters, ensuring it's not already used\n",
    "                available_files = list(set(all_files) - used_files)\n",
    "                if available_files:\n",
    "                    selected_files[character] = random.choice(available_files)\n",
    "                    used_files.add(selected_files[character])\n",
    "    \n",
    "    return selected_files\n",
    "\n",
    "# Function to convert text to speech for a character\n",
    "def voice_character(character, text, page_number, bubble_number, selected_files, save_directory):\n",
    "    speaker_wav = selected_files.get(character)\n",
    "\n",
    "    if speaker_wav:\n",
    "        audio_output_filename = name_format.format(int(page_number), 0, bubble_number+1, \".wav\")\n",
    "        output_filename = os.path.join(save_directory, audio_output_filename)\n",
    "        output = tts.tts_to_file(text=text, speaker_wav=speaker_wav, language=\"en\")\n",
    "        os.rename(\"output.wav\", output_filename)  # Rename the default output file\n",
    "        return output_filename\n",
    "    else:\n",
    "        raise ValueError(f\"Character '{character}' not found in voice mapping.\")\n",
    "\n",
    "# Function to process the transcript and create audio files\n",
    "def text2speech(pages, selected_files, save_directory):\n",
    "    output_files = []\n",
    "    time_file = []\n",
    "    \n",
    "    for page in pages: \n",
    "        page_number = page[\"page\"]\n",
    "        for bubble_number, (character, dialogue) in enumerate(page[\"lines\"]):\n",
    "            try:\n",
    "                output = voice_character(character, dialogue, page_number, bubble_number, selected_files, save_directory)\n",
    "                output_files.append(output)\n",
    "            except ValueError as e:\n",
    "                print(e)\n",
    "\n",
    "    return output_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the directory where the RAVDESS files are located\n",
    "voice_bank = \"/kaggle/input/ravdess-emotional-speech-audio/\"\n",
    "# Define male characters for the check\n",
    "male_characters = ['teacher']\n",
    "transcript_file = f\"{transcript_path}/transcript.txt\"\n",
    "\n",
    "save_directory = audio_path\n",
    "\n",
    "if os.path.exists(save_directory):\n",
    "    shutil.rmtree(save_directory)\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Get unique characters from the transcript\n",
    "pages = parse_transcript(transcript_file, line_end = 20) # delete line_end to get audio of all page\n",
    "characters = {line[0] for page in pages for line in page[\"lines\"]}  # Get unique characters\n",
    "\n",
    "# Select voice files for characters\n",
    "selected_files = select_voice_files_for_characters(characters)\n",
    "\n",
    "# # Call the function to process the transcript and generate audio files\n",
    "output_files = text2speech(pages, selected_files, save_directory)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 107620,
     "sourceId": 256618,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
